---
title: "贝叶斯统计"
author: "汪燕敏"
date: "2023-01-13"
output:
  html_document:
    df_print: paged
geometry: margin=2cm
documentclass: ctexart
---


<style type="text/css">
  body{
  font-size: 18pt;
  margin：20px
  line-height：4em
}
</style>

# 第一章 &emsp;&emsp; 贝叶斯统计简介        

## 1.什么是贝叶斯统计 

&emsp;&emsp;英国学者Thomas Bayes在其论文《Essay towards solving a problem in the doctrine of chances》中提出的一种归纳推理理论，后被一些统计学者发展为一种系统的统计推断方法，称为贝叶斯方法。     
&emsp;&emsp;认为贝叶斯方法是唯一合理的统计推断方法的统计学者组成数理统计学中的贝叶斯学派，其形成可追溯到 20世纪30年代。二战以后发展为一个有影响的学派。  

&emsp;&emsp;与之对峙的是频率学派。代表人物是英国的皮尔逊、费希尔等人和奈曼。    
&emsp;&emsp;理解贝叶斯统计必须理解贝叶斯定理。   

### **贝叶斯定理**    
&emsp;&emsp;如果有两个随机事件A,B，那么给定A,B的条件概率可以表示为
\begin{equation}
P(B|A)=\frac{P(AB)}{P(A)}=\frac{P(B)P(A|B)}{P(A)} {(1)}
\end{equation}
&emsp;&emsp;这就是概率论里的*条件概率*，也称作*贝叶斯定理*。  
&emsp;&emsp;在统计学中，如果$A$代表数据$x$，$B$代表参数$\theta$,那么公式(1)可以表示为
\begin{equation}
P(\theta|x)=\frac{P(\theta,x)}{m(x)}=\frac{\pi(\theta)P(x|\theta)}{m(x)}=\frac{\pi(\theta)L(\theta)}{m(x)} {(2)}
\end{equation}
&emsp;&emsp;这就是贝叶斯公式。$m(x)$是数据的*边缘分布*，$L$是*似然函数*,$\pi(\theta)$是参数的*先验(分布)*。        

&emsp;&emsp;由于分母$m(x)$与$\theta$无关，所以公式(2)可以表示为
\begin{equation}
P(\theta|x) \propto \pi(\theta)L(\theta)
\end{equation}
$\propto $表示"等比例于"
&emsp;&emsp;**后验分布=先验分布+样本分布**
  
&emsp;&emsp;为了比较频率学派和贝叶斯学派的范式，用一个小例子说明。   

### **一个例子**     
&emsp;&emsp;10次伯努利实验，成功1次。问成功率是多少？   
&emsp;&emsp;频率学派求点估计的思路是用极大似然法，可以得到点估计值是1/10。(证明它)   
&emsp;&emsp;贝叶斯学派认为参数和数据都是随机的。有了样本数据意味着给定数据求参数，于是我们可以根据以上信息求参数的后验分布。  
&emsp;&emsp;问题是我们需要参数的先验分布。这里采用*拉普拉斯先验*$\theta \sim U(0,1)$。   

&emsp;&emsp;于是
\[p(\theta|x) \propto L(\theta)*\pi(\theta) \propto \theta^{2-1}(1-\theta)^{10-1}*1\]

&emsp;&emsp;这是贝塔分布$Be(2,10)$密度函数的*核*。因此根据密度函数的正则性可以推出$\theta|x \sim Be(2,10)$。    

&emsp;&emsp;如果点估计取期望，则$\hat \theta= \frac {2}{12}$；    
&emsp;&emsp;如果点估计取众数(mode),则$\hat \theta= \frac {1}{10}$,与极大似然估计值相同。     
 
&emsp;&emsp;贝叶斯方法的目标是求参数的分布。给定特定的先验（共轭），可以直接得到后验分布。

&emsp;&emsp;如果不是共轭先验呢？后验分布的密度函数可以写出，但不是已知分布，往往涉及大量的积分运算。 

&emsp;&emsp;由贝叶斯定理，更新后的分布用后验分布表示为  
\begin{equation}
\pi (\theta|x)=\frac {\pi(\theta) p(x|\theta)}{\int \pi(\theta) p(x|\theta) d \theta}
\end{equation}
&emsp;&emsp;一般性的贝叶斯估计为
\begin{equation}
\hat{g(\theta)}=\frac {\int g(\theta) \pi(\theta) p(x|\theta)d \theta}{\int \pi(\theta) p(x|\theta) d \theta}
\end{equation}
&emsp;&emsp;可以看到，要得到参数$\theta$或$g(\theta)$的估计，或更为一般地，它们的后验分布，需要求得公式中的积分。在维数不是很高时可以采用数值积分或正态近似的方法。然而，在参数的维数较大时，这些方法很难实现。        
&emsp;&emsp;这时候，MCMC登场了。也就是用*随机模拟*的方法获得后验分布。    

&emsp;&emsp;因此，如果说经典统计偏向*数学方法*，那么贝叶斯统计则偏向*模拟方法*。


## 2.为什么要学贝叶斯统计    
&emsp;&emsp;贝叶斯统计与经典统计不是非此即彼的关系。对于本科生来说，两种推断方法都需要掌握。正如R和Python,掌握一门软件是不够的，必须两门都掌握。     
&emsp;&emsp;与经典统计相比，贝叶斯统计有什么优势呢？    
&emsp;&emsp;**容易学**：与经典统计相比，贝叶斯统计的理论很简单，仅仅是加了个先验和MCMC而已。       
&emsp;&emsp;**更容易解释**：考虑例1的变形。如果10次实验成功次数为0，我们得到的成功率的点估计是0。100次实验成功次数为0,1000次实验成功次数为0,成功率的点估计依然是0。尽管这从统计上是没错的，但给人的感觉是不同的。随着实验次数的增长，实验者对成功事件出现的信心会越来越弱。贝叶斯估计可以反映这一点。（基于拉普拉斯先验证明它）。       
&emsp;&emsp;考虑另一个相似的情形。某公司需要采购办公用品，三家公司来游说购买他们的产品。负责采购的领导说：“产品质量说了算”。于是组织质量检查，抽取100个产品检查次品率。结果三家企业产品的次品率都是0。极大似然法无助于决策。这个时候你了解到这三家企业一家是世界500强，另一家是中国500强，还有一家是本省500强。你会选择哪家企业呢？    
&emsp;&emsp;**样本量很小或者样本缺失**：明天联想股票是涨还是跌？这是一次性事件。极大似然估计无能为力，但贝叶斯估计可以:找专家咨询获得先验，然后求先验预测分布。   

### **3.对贝叶斯统计的批评**    
&emsp;&emsp;在MCMC应用于贝叶斯统计以前，贝叶斯方法的数学性质是很清楚的。参考Jeffreys对无信息先验的证明。    
&emsp;&emsp;但现在，贝叶斯方法越来越依赖于MCMC。Andrew Gelman说，我们不仅难以评价贝叶斯方法的统计性质，甚至不能完全确定是否收敛，仅仅添加了一些无法验证的假设。不少人将贝叶斯方法视为“伪科学”。   

## 4.**贝叶斯统计简史**    

## 4.1*贝叶斯其人*    
&emsp;&emsp;1702年出生于伦敦   
&emsp;&emsp;1719年进入爱丁堡大学学习，学习逻辑学和神学   
&emsp;&emsp;1722年毕业   
&emsp;&emsp;1733成为牧师   
&emsp;&emsp;1742年当选为皇家学会会员   
&emsp;&emsp;1752年退休   
&emsp;&emsp;1761年4月17日逝世于Kent郡   
&emsp;&emsp;1764年论文发表   

&emsp;&emsp;以上内容参考自圣安德鲁斯大学对贝叶斯的介绍。   
网址https://mathshistory.st-andrews.ac.uk/Biographies/Bayes/


## 4.2*发展过程*  
&emsp;&emsp;阶段1: 起源

&emsp;&emsp;阶段2: 荣耀的60年代The Glorious Sixties    

&emsp;&emsp;阶段3: 实效的70年代The Pragmatic Seventies    

&emsp;&emsp;阶段4: 神秘的80年代The Enigmatic Eighties   

&emsp;&emsp;阶段5: 成为明星的90年代To the Stars in the Nineties   

&emsp;&emsp;阶段6: Bayesian-Fisherian合流的21世纪

# 第二章 基础知识       
## 1. 三个分布       
### 考研大纲以外的分布       
密度函数为
\[p(x)=\frac{\lambda^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda{x}},x > 0\]
$\alpha>0$是形状参数，$\lambda>0$是尺度参数。

### Beta分布        
     
密度函数为
\[p(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta}\]
$\alpha>0,\beta>0 $

### Inv-Gamma分布         
如果$X \sim Ga(\alpha,\lambda)$,求$Y=\frac{1}{X}$的密度函数。

### Cauchy分布
密度函数为
\[p(x)=\frac{1}{\pi} \frac{1}{\lambda^2+(x-\mu)^2}\]
$\mu > 0$是形状参数，$\lambda>0$是尺度参数。

### half-Cauchy分布

密度函数为
\[p(x)=\frac{2}{\pi} \frac{1}{\lambda^2+(x-\mu)^2}, x>0\]
$\mu > 0$是形状参数，$\lambda>0$是尺度参数。

### Pareto分布
密度函数为
\[p(x)=\frac{\alpha}{\mu}(\frac{\mu}{x})^{\alpha+1},x>\mu\]

$\mu > 0$是门限参数，$\lambda>0$是尺度参数。


## 2.似然函数                  


# 第三章 R语言编程
## 对象

&emsp;&emsp;表1 R语言主要对象

 |  | 同质性对象 | 异质性对象 |
|----|----|----|
1d | atomic vectors | list |
2d | matrix | dataframe |
3d | array  |  |

## 函数表
### the first function to learn       

&emsp;&emsp; ?, str

### important operators and assignment        

&emsp;&emsp; %in%, match, =, <-, «-, $, [, [[, head, tail, subset, with, assign, get

### comparison    

&emsp;&emsp; all.equal, identical, !=, ==, >, >=, <, <=, is.na, complete.cases, is.finite       

### basic math

&emsp;&emsp; *, +, -，/, ^, %%, %/%, abs, sign, acos, asin, atan, atan2, sin, cos, tan, ceiling, floor, round, trunc,
signif, exp, log, log10, log2, sqrt, max, min, p rod, sum, cummax, cummin, cumprod, cumsum, diff, pmax,
pmin, range, mean, median, cor, sd, var, rle
### functions to do with functions

&emsp;&emsp; function, missing, on.exit, return, invisible

### logical & sets        

&emsp;&emsp; &, |, !, xor, all, any, intersect, union, setdiff, setequal, which

### vectors and matrices        

&emsp;&emsp; c, matrix

### automatic coercion rules character > numeric > logical        

&emsp;&emsp; length, dim, ncol, nrow, cbind, rbind, names, colnames, rownames, t, diag, sweep, as.matrix, data.matrix

### making vectors        

&emsp;&emsp; c, rep, rep_len, seq, seq_len, seq_along, rev, sample, choose, factorial, combn, (is/as).(character/numeric/logical/. . . )

### lists & data.frame        

&emsp;&emsp; list, unlist, data.frame, as.data.frame,
split, expand.grid

### control flow        

&emsp;&emsp; if, &&, ||, for, while, next, break, switch, ifelse

### apply & friends       

&emsp;&emsp; lapply, sapply, vapply, apply, tapply, replicate


# 第二章 &emsp;&emsp; 先验    

## 1.共轭先验 
&emsp;&emsp;定义1  设$\theta$是总体分布中的参数（或参数向量），$\pi(\theta)$是$\theta$的
先验密度函数，假如由抽样信息算得的后验密度函数与$\pi(\theta)$有相同的函数形式，
则称$\pi(\theta)$是$\theta$的*共轭先验分布*。   
&emsp;&emsp;共轭先验分布的选取是由似然函数$L(\theta)=p(x|\theta)$中所含$\theta$的因式决定的，
即选与似然函数具有相同核的分布作为先验分布。    

### 1.1 二项模型   
&emsp;&emsp;设总体$X \sim b(n,\theta)$,其密度函数中与$\theta$有关部分（核）为$\theta^x(1-\theta)^{n-x}$。
由此设$\theta$的先验分布为贝塔分布$Be(\alpha,\beta)$。求后验分布。


### 1.2 泊松模型    
&emsp;&emsp;设$x_1,\dots,x_n$是来自泊松分布$Exp(\lambda)$的一组样本观察值。
基于共轭先验求后验分布。

### 1.3 指数模型    
&emsp;&emsp;设$x_1,\dots,x_n$是来自指数分布$Exp(\lambda)$的一组样本观察值。
基于共轭先验求后验分布。   

### 1.4 正态模型（方差已知） 
&emsp;&emsp;设$x_1,\dots,x_n$是来自正态分布$N(\theta,\sigma^2)$的一组样本观察值。
其中$\sigma_2$已知。基于共轭先验求后验分布。

### 1.5 正态模型（均值已知）    
&emsp;&emsp;设$x_1,\dots,x_n$是来自正态分布$N(\theta,\sigma^2)$的一组样本观察值。其中$\theta$
已知。现取倒伽玛分布$Ga(\alpha,\lambda)$作为正态方差$\sigma^2$的先验分布(不是$\sigma$)。
其中$\alpha$和$\lambda$已知。基于共轭先验求后验分布。

&emsp;&emsp;表1 常用共轭先验分布

|总体分布 | 参数 | 共轭先验分布|
|---- | ---- | ----|
|二项分布 | 成功概率 | 贝塔分布|
|泊松分布 | 均值|伽玛分布|
|指数分布 | 均值的倒数|伽玛分布|
|正态分布（方差已知） | 均值|正态分布|
|正态分布（均值已知） | 方差|伽玛分布|


## 2.无信息先验  

**如果没有先验信息，如何确定先验分布？**    
&emsp;&emsp;Bayes用的是贝叶斯假设，就是拉普拉斯先验。什么场合可使用贝叶斯假设？    

如果不能使用贝叶斯假设，无信息先验又如何确定？    

&emsp;&emsp;首先要知道该参数$\theta$在总体分布中的地位，是位置参数，还是尺度参数？    

&emsp;&emsp;根据参数在分布的地位选用适当变换下的不变性来确定其无信息先验。

&emsp;&emsp;当$\theta$为位置参数时，其先验分布可用贝叶斯假设作为无信息先验。    

&emsp;&emsp;当$\theta$为尺度参数时，其先验分布不可以用贝叶斯假设作为无信息先验。

&emsp;&emsp;求无信息先验大致有三种方法：Jeffreys先验,reference先验,概率匹配先验。   

### *Jeffreys先验 *   
&emsp;&emsp;Jeffreys(1961)用Fisher信息量（阵）给出参数$\theta$的无信息先验。    
&emsp;&emsp;C-R正则族是Fisher信息量（阵）存在的条件。常用分布族大多属于C-R正则族。
&emsp;&emsp;无信息先验公式如下
\[\pi(\theta)=|I(\theta)|^{\frac{1}{2}}\]
即Fisher信息量（阵）行列式的平方根。    

&emsp;&emsp;例1：设$x_1,\dots,x_n$是来自正态分布$N(\theta,\sigma^2)$的一组样本观察值。
求参数向量$(\mu,\sigma)$的Jeffreys先验。    

&emsp;&emsp;例2.求二项模型成功概率的Jeffreys先验。    

## 3.弱信息先验   
&emsp;&emsp;弱信息先验意味着未知参数先验分布的方差很大，也就是关于参数的信息很少，很不确定。

&emsp;&emsp;比如在正态模型（方差已知）中，$y_i \sim N(\theta,\sigma^2)$，并且$\theta \sim N(\mu,\tau^2)$。
如果$\tau=100$,则$\tau^2=100^2$,方差就很大了。    

&emsp;&emsp;也可以设$\tau \sim C(\mu,\lambda)$。因为柯西分布没有期望和方差，被视为弱信息分布。当参数非负时，经常采用半柯西分布。    


# 第三章 &emsp;&emsp; 贝叶斯计算与MCMC 

## 什么是MCMC   
&emsp;&emsp;贝叶斯统计分析涉及很多积分运算，特别是后验积分的积分运算。    
&emsp;&emsp;考虑如下积分
\[\hat {g(\theta)}=\int{g(\theta)\pi(\theta |x)}d\theta\]
即$g(\theta)$的后验均值$E[(g(\theta)|x)]$。显然，可以用下面的平均值近似求得。
\[\bar {g}= \frac{1}{m}\sum_{i=1}^{m}g(\theta^{(i)})\]
&emsp;&emsp;其中$\theta^{(1)},\dots,\theta^{(m)}$是来自后验分布$\pi(\theta |x)$的容量为$m$的样本。
&emsp;&emsp;如果此样本为独立的，则由大数定理，样本均值$\bar {g}$依概率收敛到$E[(g(\theta)|x)]$。这种技术称为蒙特卡洛（Monte Carlo）方法。    
&emsp;&emsp;但是在有些问题中，从$\pi(\theta |x)$抽取独立的样本非常困难。然而，如果通过某种方法可以获得从
$\pi(\theta |x)$的一个非独立“样本”（严格地讲是一条链在一些状态下的值），但具有一些好的性质，
且与从$\pi(\theta |x)$中抽取的独立样本的作用是一样的，那么蒙特卡洛方法仍然可以使用。
这就是蒙特卡洛马尔科夫链（Monte Carlo Markov Chain，MCMC）。    
&emsp;&emsp;因此，MCMC就是基于马尔科夫链从目标分布抽取随机“样本”，用平均值估计积分。    
&emsp;&emsp;单参数模型的抽样比较简单，这里分析多参数模型。    
&emsp;&emsp;在多参数模型中，一般先考虑是否可以直接得到某参数或参数的函数的后验分布；    
&emsp;&emsp;若无法得到其显式表示，则再考虑是否可以将联合后验分布进行分解，然后进行分步抽样，
其优点是无需进行收敛性判断。        
&emsp;&emsp;在分解方法都无法进行时再考虑Gibbs抽样等MCMC方法，但需要对马尔科夫链的收敛性进行判断。   
&emsp;&emsp;大量复杂的统计模型都用最后一种方法解决，因此具有普遍的意义。       

## Gibbs抽样
&emsp;&emsp;需要参数的满条件后验分布。    
&emsp;&emsp;在Gibbs抽样中，称
\[\pi(\theta_j|\theta_{-j},x)=\frac{\pi(\theta_j|\theta_1,\cdots,\theta_{j-1},\theta_{j+1},\cdots|x)}
{\int \pi(\theta_j|\theta_1,\cdots,\theta_{j-1},\theta_{j+1},\cdots|x)d{\theta_j}}\]
为$\theta_j$的满条件后验分布(full conditional distribution)

&emsp;&emsp;假设模型有$p$个参数。   
&emsp;&emsp;算法如下：       
&emsp;&emsp;1.给定参数的初始值：$\theta_1^{(0)},\dots,\theta_p^{(0)}$;     
&emsp;&emsp;2.对$t=0,1,2,\dots$进行下面的迭代更新   
&emsp;&emsp;a)从分布$\pi(\theta_1|\theta_2^{(t)},\dots,\theta_p^{(t)},x)$中产生$\theta_1^{(t+1)}$;    
&emsp;&emsp;b)从分布$\pi(\theta_2|\theta_1^{(t)},\theta_3^{(t)},\dots,\theta_p^{(t)},x)$中产生$\theta_2^{(t+1)}$;    
&emsp;&emsp;$\cdots$      
&emsp;&emsp;c)从分布$\pi(\theta_p|\theta_1^{(t)},\theta_2^{(t)},\dots,\theta_{p-1}^{(t)},x)$中产生$\theta_2^{(t+1)}$;

&emsp;&emsp;由此产生马尔科夫链$\theta^{(0)},\theta^{(1)},\cdots,\theta^{(t)},\cdots$。 

### 例子 

&emsp;&emsp;$X,Y$服从二元正态分布，联合密度函数为
\[f(x,y)=\frac{1}{2\pi \sqrt(1-\rho^2)} exp{(-\frac{1 }{2(1-\rho^2) }(x^2-xy+y^2))}\]
&emsp;&emsp;边缘分布为
\[X|Y \sim N(\rho y,1-\rho^2)\]
\[Y|X \sim N(\rho x,1-\rho^2)\]

```{r cache=TRUE}
# 
# Function to sample from a bivariate normal distribution
Gibbs_bivariate_normal <- function(N = 1000, rho = 0,  
                                   x_0 = -5, y_0 = 4, do.plots = TRUE)
{
    # N: number of iterations
    # rho: correlation
    # x_0 and y_0: the initial values of the x and y sequences
    # do.plots: should traceplots and autocorrelation plots be produced
    # Set up vectors to hold the simulated values
    x <- rep(NA, N + 1)
    y <- rep(NA, N + 1)
    # Set the initial values
    # Remember, R vectors are indexed from 1
    x[1] <- x_0
    y[1] <- y_0
    # Sample from the appropriate conditional distributions
    for(i in 2:(N  + 1)){
        # This is where you need to modify the code to sample -ONE- value 
        # from the appropriate conditional distribution 
        x[i] <- rnorm(1,mean = rho*y[i-1],sd=1-rho^2)  
        y[i] <- rnorm(1,mean = rho*x[i],sd=1-rho^2) 
    }
    # Remove burn-in
    x_ergodic <- x[(N/2 + 1):(N+1)]
    y_ergodic <- y[(N/2 + 1):(N+1)]
    # Some plots
    if(do.plots){
        p <- par(mfrow = c(3,2), mar = c(4.1, 5.1, 3.1, 1.1))
        plot(0:N, x, xlab = "Iteration i", ylab = expression(x^(i)), type = "l")
        abline(v = (N/2 + 1) - 0.5 - 1, col = "red", lwd = 2)
        #
        plot(0:N, y, xlab = "Iteration i", ylab = expression(y^(i)), type = "l")
        abline(v = (N/2 + 1) - 0.5 - 1, col = "red", lwd = 2)
        #
        plot(((N/2 + 1):(N+1)) - 1, x_ergodic,  xlab = "Iteration i", ylab = expression(x^(i)), sub = "After burn-in", type = "l")
        #
        plot(((N/2 + 1):(N+1)) - 1, y_ergodic,  xlab = "Iteration i", ylab = expression(y^(i)), sub = "After burn-in", type = "l")
        #
        acf(x_ergodic, main = "Autocorrelation Function of x values\nafter burn-in",
            lag.max = 15)
        acf(y_ergodic, main = "Autocorrelation Function of y values\nafter burn-in",
            lag.max = 15)
        #
        par(p)
        }
    #
    return(list(x = x, y = y, x_ergodic = x_ergodic, y_ergodic = y_ergodic))
}

g_bvn_0.8 <- Gibbs_bivariate_normal(N = 10000, rho = 0.8,  x_0 = -5, y_0 = 4)

# Save the results in a nice format

x <- g_bvn_0.8$x; y <- g_bvn_0.8$y
x_ergodic <- g_bvn_0.8$x_ergodic; y_ergodic <- g_bvn_0.8$y_ergodic

# Monte Carlo approximations
#E[X] = 0,E[Y] = 0;Var[X] = 1,Var[X] = 1
mean(x_ergodic);mean(y_ergodic)  
var(x_ergodic); var(y_ergodic) 
cor(x_ergodic, y_ergodic) # cor[X, Y] = rho
```


## MH抽样
&emsp;&emsp;如果某个满条件分布不容易抽样，则可以借助Metropilis-Hastings算法(MH算法)进行抽样。    
&emsp;&emsp;MH算法需要建议分布。    
&emsp;&emsp;算法如下：    
&emsp;&emsp;1.构造合适的建议分布$q(\cdot|\theta^{(t)})$;    
&emsp;&emsp;2.从某个分布$g$中产生$\theta^{(0)}$;    
&emsp;&emsp;3.重复下面过程，直至马尔科夫链达到平衡状态      
&emsp;&emsp;a)从$q(\cdot|\theta^{(t)})$中产生候选点$\theta^{(cand)}$;    
&emsp;&emsp;b)从均匀分布$U(0,1)$中产生U;    
&emsp;&emsp;c)判断：如果$U \le \frac{\pi(\theta^{(cand)}|x)q(\theta^{(t))}|\theta^{(cand)})}{\pi(\theta^{(t)}|x)q(\theta^{(cand)}|\theta^{(t)})}$，则接受$\theta^{(cand)}$，并令$\theta^{(t+1)}=\theta^{(cand)}$，否则令$\theta^{(t+1)}=\theta^{(t)}$;    
&emsp;&emsp;d)增加$t$，返回到a)。    
&emsp;&emsp;Gibbs抽样法是一种特殊的MH算法，其中的每一个候选点都被接受。   
&emsp;&emsp;MH算法具有普遍意义。 

### 例1    

&emsp;&emsp;投掷硬币，正面为1，反面为0。得到的数据为(1,1,1,1,1,1,1,1,1,1,1,0,0,0)。用MH方法估计正面的概率。

```{r cached = TRUE}
# specifiy the data
mydata <- c(1,1,1,1,1,1,1,1,1,1,1,0,0,0)
# define the likelihood function
likelihood <- function(theta,data){
z <- sum (data == 1)
N <- length(data)
pdata <- theta^z+(1-theta)^(N-z)
return(pdata)
}
# define the prior
prior <- function(theta){
priorDist <- rep(1,length(theta))
return(priorDist)
}
# define the relative probability of the target distribution
target <- function(theta,data){
targetp <- likelihood(theta,data) * prior(theta)
return(targetp)
}
# specify the length of trajectory,i.e., the no. of jumps to try
trajlength <- 10^4
trajectory <- rep(0,trajlength);trajectory[1] <- 0.5
nAccepted <- 0
set.seed(47405)
# Now generate the random walk
for (t in 2:trajlength) {
  currentVal = trajectory[t]
  proposal = rnorm(1, mean = currentVal,sd = 0.1)
  probAccept = min(1,target(proposal,mydata)/target(currentVal,mydata))
  if (runif(1) < probAccept){
  trajectory[t+1] = proposal
  nAccepted = nAccepted + 1
  }else {
  trajectory[t+1] = currentVal
  }

}
#
acceptance_rate = nAccepted/trajlength
plot(0:trajlength, trajectory, type = "l",
xlab = "Iteration",
ylab = expression(theta[1]),
main = paste0("Acceptance rate ", acceptance_rate))
#
abline(v = (trajlength / 2 + 1) - 0.5 - 1,
lwd = 2,
col = "green") # Show burn-in

mean(trajectory[trajlength / 2:trajlength]);
sd(trajectory[trajlength / 2:trajlength])
```


### 例2 
&emsp;&emsp;假设参数$\theta_1,\theta_2$服从二元正态分布
\[\pi(\theta_1,\theta_2)=(\theta_1+\theta_2)/8\]
&emsp;&emsp;我们可以分别得到两个参数的边缘分布
\[\pi(\theta_1|\theta_2)=\frac {\theta_1+\theta_2}{2(1+\theta_2)}\]
\[\pi(\theta_2|\theta_1)=\frac {\theta_1+\theta_2}{2(1+\theta_1)}\]
&emsp;&emsp;从一个建议分布（proposal distribution）产生备选点，是否接受这个点的概率为
\[\alpha=min(1,\frac {q(\theta_1^{(i-1)})\pi(\theta_1^{(cand)}|\theta_2^{(i-1)})}
{q(\theta_1^{(cand)})\pi(\theta_1^{(i-1)}|\theta_2^{(i-1)})})\]
&emsp;&emsp;因为$q(\theta_1^{(i-1)})=q(\theta_1^{(cand)})=\frac {1}{b-a}$。所以
$\alpha=min(1,\frac{\pi(\theta_1^{(cand)}|\theta_2^{(i-1)})}{\pi(\theta_1^{(i-1)}|\theta_2^{(i-1)})})$

&emsp;&emsp;代码如下：   
```{r cache=TRUE}
# Code to implement sampling from the simple
# bivariate probability density function
# pi(theta_1, theta_2) = (theta_1 + theta_2) / 8
# theta_1, theta_2 in [0,2]
pi_theta_1_given_theta_2 <- function(theta_1, theta_2){
  (theta_1 + theta_2) / (2*(1 + theta_2))
}
#
pi_theta_2_given_theta_1 <- function(theta_2, theta_1){
  (theta_1 + theta_2) / (2*(1 + theta_1))
}
# The Metropolis sampling algorithm
# using the above conditional probability density functions
N <- 5000 # We will use a large number of iterations
# Space for theta_1 and theta_2
theta_1 <- rep(NA, N + 1)
theta_2 <- rep(NA, N + 1)
# Initial values of our choice
theta_1[1] <- 0.8
theta_2[1] <- 0.2
# Metropolis algorithm
for(i in 2:(N+1)){
  # theta_1
  theta_1_cand <- runif(1, 0, 2) # Sample one realization from U[0,2]
  # Ratio of conditionals
  ratio <- pi_theta_1_given_theta_2(theta_1_cand, theta_2[i-1]) /
    pi_theta_1_given_theta_2(theta_1[i-1], theta_2[i-1])
  #
  alpha <- min(1, ratio)
  u <- runif(1, 0, 1)
  # Decide whether or not to accept the candidate point by generating u from U[0,1]
  theta_1[i] <- ifelse(u <= alpha, theta_1_cand, theta_1[i-1])
  # If u <= alpha, accept the candidate point, otherwise do not move
  # theta_2
  theta_2_cand <- runif(1, 0, 2) # Sample one realization from U[0,2]
  # Ratio of conditionals
  ratio <- pi_theta_2_given_theta_1(theta_2_cand, theta_1[i]) /
    pi_theta_2_given_theta_1(theta_2[i-1], theta_1[i])
    # The latest version of theta_1 is used
  alpha <- min(1, ratio)
  u <- runif(1, 0, 1)
  # Decide whether or not to accept the candidate point by generating u from U[0,1]
  theta_2[i] <- ifelse(u <= alpha, theta_2_cand, theta_2[i-1])
# If u <= alpha, accept the candidate point, otherwise do not move
}
# Extract values from the ergodic phase
theta_1_ergodic <- theta_1[(N/2 + 1):(N + 1)];theta_2_ergodic <- theta_2[(N/2 + 1):(N + 1)]
# Monte Carlo approximations
# Random variable means
mean(theta_1_ergodic);mean(theta_2_ergodic)
# Random variable variances
var(theta_1_ergodic);var(theta_2_ergodic)
# Random variable standard deviations
sd(theta_1_ergodic);sd(theta_1_ergodic)
# Correlation between the random variables
cor(theta_1_ergodic, theta_2_ergodic)

```


### 例3        
&emsp;&emsp;有两个硬币，一个来自加拿大，一个来自印度。$\theta_1,\theta_2$分别是两硬币出现人头的概率。        
\[p(\theta_1,\theta_2) = p(\theta_1) p(\theta_2) \]
\[p(y_1|\theta_1,\theta_2) = p(y_1|\theta_1), p(y_2|\theta_1,\theta_2)p(y_2|\theta_2)\]
\[p(D|\theta_1,\theta_2)=\prod _{y_{1i}\in D_1}p(y_{1i}|\theta_1,\theta_2)\prod _{y_{2i}\in D_2}p(y_{2i}|\theta_1,\theta_2)\]

```{r cached = TRUE}
#define the likelihood function.
#the input argument is a vector:theta=c(theta_1,theta_2)
likelihood = function(theta){
z1=5;N1=7;z2=2;N2=7

likelihood=(theta[1]^(z1)*(1-theta[1])^(N1-z1))
(theta[2]^(z2)*(1-theta[2])^(N2-z2))
return(likelihood)
}
#define the prior
prior = function(theta){
#here's a beta-beta prior
a1=3;b1=3;a2=3;b2=3

prior = dbeta(theta[1],a1,b1)*dbeta(theta[2],a2,b2)
return(prior)
}
#define the relative prop of the target distribution
target = function(theta){
target = likelihood(theta)*prior(theta)
}
trajlength = 10^4
trajectory = matrix(0,nrow = trajlength, ncol = 2)
trajectory[1,]=c(0.5,0.5)
nAccepted = 0
set.seed(12345)
covmat = matrix(c(0.2^2,0,0,0.2^2),nrow=2, ncol=2)
for (i in 1:(trajlength-1)){
  current = trajectory[i,]
  proposal = MASS::mvrnorm(n = 1,mu = current,Sigma = covmat)
  propAccept = min(1,target(proposal)/target(current))
  if(runif(1) < propAccept){
  trajectory[i+1,] = proposal
  nAccepted = nAccepted + 1
  } else {
  trajectory[i+1,] = current
  }
}
theta_ergodic <- trajectory[trajlength/2:trajlength,]
meanTraj <- apply(theta_ergodic,2,mean);meanTraj
sdTraj <- apply(theta_ergodic,2,sd);sdTraj
```


## 汉密尔顿抽样   
&emsp;&emsp; MH可能会造成两个问题：    
&emsp;&emsp; a)如果建议分布是对称的，计算$\alpha$时会被消掉，可能会花费很长时间才能收敛到平衡分布；            
&emsp;&emsp; b)MH算法的拒绝率和transition kernel有关，我们希望拒绝率尽量低。       
Hamiltonian Monte Carlo（HMC）算法能很好的缓解上面的两个问题。        
  
&emsp;&emsp; 后验分布为
\[\pi(\theta_1,\theta_2,\cdots,\theta_d|y)\]
增加辅助变量$r_1,r_2,\cdots,r_d$,辅助变量的概率密度为$\pi(r_1,r_2,\cdots,r_d)$。
该估计参数和辅助变量的联合分布定义为
\[\pi(\theta_1,\theta_2,\cdots,\theta_d,r_1,r_2,\cdots,r_d|y)：= \pi(\theta_1,\theta_2,\cdots,\theta_d|y)\pi(r_1,r_2,\cdots,r_d)\]
或者向量表示为
\[\pi(\theta,r|y) = \pi(\theta|y)\pi(r)\]
定义汉密尔顿系统为
\begin{equation}
\begin{split}
& H(\pi(\theta_1,\theta_2,\dots,\theta_d,r_1,r_2,\dots,r_d|y):= -log(\pi(\theta,r|y) )\\
& =-log(\pi(\theta|y)\pi(r))\\
& =-log(\pi(\theta|y))-log(\pi(r))\\
& = T(r|\theta) + V(r)
\end{split}
\end{equation}
第一项表示动量能，第二项表示势能。因为两者是独立的，$\pi(r|\theta)$=$\pi(r)$。

\[\frac{d\theta}{dt}=+\frac{\partial{T}}{\partial{r}}\]
\[\frac{dr}{dt}=-\frac{\partial{V}}{\partial{\theta}}\]

&emsp;&emsp;具体算法如下：   

输入：起点$\theta_1$和步长$\epsilon$
for $t=1,2,\cdots$ do

对动量$r$进行取样
\[r(t)=N(0,M)\]
\[(\theta_0,r_0)=(\theta^{(t)},r^{(t)})\]
模拟汉密尔顿动力学的离散化
\[r_0 \gets r_0- \frac {\epsilon}{2} \nabla U(\theta_0) \]
for $i=1$ to $m$ do
\[\theta_i \gets \theta_{i-1}- \epsilon M^{-1} r_{i-1}\]
\[r_i \gets r_{i-1}- \epsilon \nabla U(\theta_m)\]
end
\[r_m \gets r_{m}-\frac {\epsilon}{2} \nabla U(\theta_m)\]
\[(\hat{\theta},\hat{r})=(\theta_m,r_m)\]
Metropolis-Hastings correction:       
\[u \sim Uniform(0,1)\]
\[\rho = e^{H(\hat{\theta},\hat{r})-H(\theta_m,r_m)}\]
if $u < min(1,\rho)$ ,then $\theta^{(t+1)}=\hat{\theta}$
以上算法的代码如下，
```{r}
rm(list=ls())
set.seed(123456)
rho=0.8
U <- function(q){
  # Please note: additive constant removed
  (q[1]^2 - 2 * rho * q[1] * q[2] + q[2]^2) / (2 * (1 - rho^2))
  }
# Derivatives (hand coded)
grad_U <- function(q){
 c((q[1] - rho * q[2] ) / (1 - rho^2),
   (q[2]  - rho * q[1]) / (1 - rho^2)) 
}

 HMC = function (U, grad_U, epsilon=0.3, L=20, current_q) {
  mvmat=matrix(c(1,0,0,1),nrow=2,ncol = 2)
  q = current_q;  p = MASS::mvrnorm(1, mu=c(0,0), Sigma=mvmat)
  current_p = p
  # Make a half step for momentum at the beginning
    p = p - epsilon * grad_U(q) / 2;
  
  # Alternate full steps for position and momentum
  
  for (j in 1:L)  {
    # Make a full step for the position
    
    q = q + epsilon * p
    
    # Make a full step for the momentum, except at end of trajectory
    
    if (j!=L) p = p - epsilon * grad_U(q)
    }
  
  # Make a half step for momentum at the end.
  
  p = p - epsilon * grad_U(q) / 2
  
  
  # Negate momentum at end of trajectory to make the proposal symmetric
  
  p = -p
  
  # Evaluate potential and kinetic energies at start and end of trajectory
  
  current_U = U(current_q);  current_K = sum(current_p^2) / 2
  proposed_U = U(q);  proposed_K = sum(p^2) / 2
  # Accept or reject the state at end of trajectory, returning either
  # the position at the end of the trajectory or the initial position
  result <- ifelse(runif(1) < exp(current_U-proposed_U+current_K-proposed_K),
                   q,current_q)
  return(result)
  
}
trajlength = 10^4
traj = matrix(rep(0,trajlength),nrow =trajlength ,ncol = 2);traj
traj[1,]=c(0.5,0.3)
current_q=traj[1,]

for (i in 2:trajlength) {
    traj[i,] = HMC(U, grad_U, epsilon=0.3, L=20,current_q=traj[i-1,])
}
traj

```
以上代码的参数估计是向量化的，下面的是分开估计的。
&emsp;&emsp;代码如下：
```{r cached = TRUE}
# Plot the probability density function
bivariate_normal_pdf <- function(theta_1, theta_2, rho){
  exp(-(theta_1^2 - 2 * rho * theta_1 * theta_2 + theta_2^2) / (2 * (1 - rho^2))) / (2 * pi * sqrt(1 - rho^2))
}

bivariate_normal_pdf_log <- function(theta_1, theta_2, rho){
  # Please note: additive constant removed
  -(theta_1^2 - 2 * rho * theta_1 * theta_2 + theta_2^2) / (2 * (1 - rho^2))
  #
}
# Derivatives (hand coded)
d_log_pdf_d_theta_1 <- function(theta_1, theta_2, rho){
  - (theta_1 - rho * theta_2) / (1 - rho^2)
}

d_log_pdf_d_theta_2 <- function(theta_1, theta_2, rho){
  #
  - (theta_2 - rho * theta_1) / (1 - rho^2)
}

plot_bivariate_normal_pdf <- function(rho, 
                                      n_theta_1 = 100,
                                      n_theta_2 = 100,
                                      theta_1_lim = c(-3,3),
                                      theta_2_lim = c(-3,3),
                                      n_levels = 25,
                                      col = "black", add = FALSE){
  # Sequences of points
  theta_1_seq <- seq(from = theta_1_lim[1],
                     to = theta_1_lim[2],
                     length = n_theta_1)

  theta_2_seq <- seq(from = theta_2_lim[1],
                     to = theta_2_lim[2],
                     length = n_theta_2)

  f_mat <- matrix(NA, 
                  nrow = n_theta_1,
                  ncol = n_theta_2)

  for(i in 1:n_theta_1){
    for(j in 1:n_theta_2){
      f_mat[i,j] <- bivariate_normal_pdf(theta_1_seq[i], theta_2_seq[j], rho)
    }
  }

  contour(theta_1_seq,
          theta_2_seq,
          f_mat,
          xlab = expression(theta[1]),
          ylab = expression(theta[2]),
          nlevels = n_levels,
          col = col,
          add = add)
}
# Check
par(mfrow=c(1,3))
plot_bivariate_normal_pdf(rho = 0.8)      
plot_bivariate_normal_pdf(rho = 0.0)
plot_bivariate_normal_pdf(rho = -0.8)

# Now the Hamiltonian Monte Carlo algorithm
log_pdf_momentum <- function(phi_1, phi_2, 
                             sigma_1, sigma_2){
  dnorm(phi_1, 0, sigma_1, log = TRUE) + dnorm(phi_2, 0, sigma_2, log = TRUE)
}

HMC_bivariate_normal <- function(rho = 0.8,
                                 niter = 1000,
                                 theta_1_initial = 6,
                                 theta_2_initial = 6,
                                 theta_1_lim = c(-6,6),
                                 theta_2_lim = c(-6,6),
                                 L = 20,
                                 epsilon = 0.3,
                                 sigma_1 = 1,
                                 sigma_2 = 1,
                                 plot_first_number = 30,
                                 col = "black") {
  # rho: correlation of bivariate normal distribution from which we want to sample
  # niter: number of algorithm iterations
  # theta_1_initial, theta_2_initial: initial values for theta_1 and theta_2
  # L: number of leapfrog iterations
  # epsilon: step size for updates of phi and theta
  # sigma_1, sigma_2: tuning paramters for the update of phi_1 and phi_2
  # sigma_1^2 = M_1 of the notes, sigma_2^2 = M_2 of the notes
  # plot_first_number: show this nuber on a plot
  # col: colour for contour plot
  # Space
  theta_1_vec <- rep(NA, niter + 1) # Space for initial value
  theta_2_vec <- rep(NA, niter + 1) # Space for initial value
  #
  phi_1_vec <- rep(NA, niter + 1)
  phi_2_vec <- rep(NA, niter + 1)
  #
  phi_1_consequence <- rep(NA, niter + 1)
  phi_2_consequence <- rep(NA, niter + 1)
  # The matrix M
  M <- diag(c(sigma_1^2, sigma_2^2))
  M_inv <- diag(c(1 / sigma_1^2, 1 / sigma_2^2))
  # Initialize theta values
  theta_1_vec[1] <- theta_1_initial
  theta_2_vec[1] <- theta_2_initial
  # Save these values in theta_1 and theta_2 for later updating
  theta_1 <- theta_1_vec[1]
  theta_2 <- theta_2_vec[1]
  # ***** Hamiltonian updates *****
  # Record the number of acceptance
  no_accept <- 0

  for(i in 2:(niter + 1)){
    # Update phi
    phi_1 <- rnorm(1, 0, sigma_1)
    phi_2 <- rnorm(1, 0, sigma_2)
    # Save the old point for later use 
    # in the accept/reject step
    theta_1_old <- theta_1_vec[i - 1]
    theta_2_old <- theta_2_vec[i - 1]
    #
    phi_1_old <- phi_1
    phi_2_old <- phi_2
    # Leapfrog
    for(l in 1:L){
      # Half step for phi (can be vectorized)
      phi_1 <- phi_1 + epsilon * d_log_pdf_d_theta_1(theta_1, theta_2, rho) / 2
      phi_2 <- phi_2 + epsilon * d_log_pdf_d_theta_2(theta_1, theta_2, rho) / 2
      # Record these points
      phi_1_consequence[i] <- phi_1
      phi_2_consequence[i] <- phi_2
      # Full step for theta (vectorized)
      theta_1_2 <- c(theta_1, theta_2) + epsilon * M_inv %*% c(phi_1, phi_2)
      #
      theta_1 <- theta_1_2[1]
      theta_2 <- theta_1_2[2]
      # Half step for phi (can be vectorized)
      phi_1 <- phi_1 + epsilon * d_log_pdf_d_theta_1(theta_1, theta_2, rho) / 2
      phi_2 <- phi_2 + epsilon * d_log_pdf_d_theta_2(theta_1, theta_2, rho) / 2
      #
    }
    # So now after all this leapfrogging about we have candidate values for theta and phi
    theta_1_cand <- theta_1
    theta_2_cand <- theta_2
    #
    phi_1_cand <- phi_1
    phi_2_cand <- phi_2
    # Compute ratio, on log scale
    #
    log_r_theta <- bivariate_normal_pdf_log(theta_1_cand, theta_2_cand, rho) - bivariate_normal_pdf_log(theta_1_old, theta_2_old, rho)
    log_r_phi <- log_pdf_momentum(phi_1_cand, phi_2_cand, sigma_1, sigma_2) - log_pdf_momentum(phi_1_old, phi_2_old, sigma_1, sigma_2)
    #
    log_r <- log_r_theta + log_r_phi
    #
    log_alpha <- min(0, log_r)
    # Accept or reject
    u <- runif(1)
    #
    log_u <- log(u)
    #
    if(log_u <= log_alpha){
      # Accept
      no_accept <- no_accept + 1 # Record it
      #
      theta_1_vec[i] <- theta_1_cand
      theta_2_vec[i] <- theta_2_cand
      #
      phi_1_vec[i] <- phi_1_cand
      phi_2_vec[i] <- phi_2_cand
      #
    } else {
      # Reject
      theta_1_vec[i] <- theta_1_old
      theta_2_vec[i] <- theta_2_old
      #
      phi_1_vec[i] <- phi_1_old # Who cares?  Useful for monitoring, I think.
      phi_2_vec[i] <- phi_2_old # Who cares?  Useful for monitoring, I think.
    }

  } # End of niter updated
  # Acceptance rate
  acceptance_rate <- no_accept/ niter
  print(paste("Acceptance rate is", acceptance_rate))
  # Ergodic phase
  theta_1_ergodic <- theta_1_vec[(niter / 2 + 1):(niter + 1)]
  theta_2_ergodic <- theta_2_vec[(niter / 2 + 1):(niter + 1)]
  #
  phi_1_ergodic <- phi_1_vec[(niter / 2 + 1):(niter + 1)]
  phi_2_ergodic <- phi_2_vec[(niter / 2 + 1):(niter + 1)]
  #
  phi_1_consequence_ergodic <- phi_1_consequence[(niter / 2 + 1):(niter + 1)]
  phi_2_consequence_ergodic <- phi_2_consequence[(niter / 2 + 1):(niter + 1)]
  # Some plots
  par(mfrow = c(6,2))
  #
  plot(0:niter, theta_1_vec, type = "l",
       xlab = "Iteration",
       ylab = expression(theta[1]),
       main = paste0("Acceptance rate ", acceptance_rate, 
                     ", L = ", L,
                     ", epsilon = ", epsilon))
  #
  abline(v = (niter / 2 + 1) - 0.5 - 1, 
         lwd = 2,
         col = "green") # Show burn-in
  #
  plot(0:niter, theta_2_vec, type = "l",
       xlab = "Iteration",
       ylab = expression(theta[2]),
       main = paste0("Acceptance rate ", acceptance_rate, 
                     ", L = ", L,
                     " , epsilon = ", epsilon))
  #
  abline(v = (niter / 2 + 1) - 0.5 - 1, lwd = 2,
         col = "green") # Show burn-in
  # acf for ergodic phase
  acf(theta_1_ergodic)
  title(sub = paste("Sum of squared values", signif(sum(acf(theta_1_ergodic, plot = FALSE)$acf^2), 4)))
  acf(theta_2_ergodic)
  title(sub = paste("Sum of squared values", signif(sum(acf(theta_2_ergodic, plot = FALSE)$acf^2), 4)))
  #
  plot(0:niter, phi_1_vec, type = "l",
       xlab = "Iteration",
       ylab = expression(phi[1]))
  #
  abline(v = (niter / 2 + 1) - 0.5 - 1, lwd = 2,
         col = "green") # Show burn-in
  #
  plot(0:niter, phi_2_vec, type = "l",
       xlab = "Iteration",
       ylab = expression(phi[2]))
  #
  abline(v = (niter / 2 + 1) - 0.5 - 1, lwd = 2,
         col = "green") # Show burn-in

}
```


# 第四章&emsp;&emsp; MCMC与RStan   

## 什么是Rstan？       
&emsp;&emsp; 目前可用于贝叶斯计算的软件包括WinBUGS, OpenBUGS，JAGS（Just Another Gibbs Sampler）和Stan。WinBUGS和OpenBUGS隶属于BUGS（Bayesian Inference Using Gibbs Sampling）项目。该项目由剑桥大学医学研究委员会生物统计部（The Medical Research Council Biostatistics Unit）主持，启动于1989年。最初的版本是运行在linux上的，后来移植到Windows下发展成为WinBUGS（与帝国理工医学院合作）。WinBUGS已经停止更新，上一次发布是在2007年8月。OpenBUGS是赫尔辛基大学开发的WinBUGS的开源版本，最后一次发布是在2014年。JAGS是英国华威大学 Martyn Plummer基于BUGS语言开发的。Stan项目以提出蒙特卡洛方法的 Stanislaw Ulam命名，由哥伦比亚大学的Andrew Gelman带领团队开发。       
&emsp;&emsp; Stan和JAGS可以用于相同的问题，但两者有着显著不同。JAGS是BUGS的变体，类似于WinBUGS和OpenBUGS，模型仅说明变量之间的关系。而Stan里的模型被明确定义为几个部分，其中语句的顺序对执行是有影响的。WinBUGS和OpenBUGS都是用Component Pascal编写的，这是一种小众语言，开发难度很大。JAGS和Stan都用C++编写。而且JAGS和Stan都是跨平台的，也可以在64-bit平台上以64-bit应用来进行编译。因此，初学者的选择无非是JAGS抑或Stan。        
&emsp;&emsp; RStan是Stan的R接口。它有个对应的“rstan”包在CRAN上发布，其源代码托管在GitHub上。        

## Rstan的结构        
&emsp;&emsp; 基于RStan求解贝叶斯模型的流程如下：   
&emsp;&emsp; ①指定环境   
```{r message=FALSE}
# install.packages("StanHeaders", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
# install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(rstan) #加载包
options(mc.cores = parallel::detectCores()) #并行估计模型
rstan_options(auto_write = TRUE) #将已编译的Stan程序保存到硬盘上
```
&emsp;&emsp; 前两行代码是为了安装低版本的rstan，因为最新版本的rstan与R4.2兼容。              
&emsp;&emsp; 后两行代码不是必需的，但可以在一定程度上提高运行速度。    
&emsp;&emsp; ②编写一个Stan程序   
&emsp;&emsp; 通过使用Stan建模语言编写其对数后验密度来表示统计模型。可以使用带有.stan扩展名的文本文件。也可以使用R中的字符串来完成，并以文本文件写入硬盘。    
&emsp;&emsp; Stan程序一般分为三个模块：data、parameters和model。data需要定义两类：样本容量n和数据。parameters模块指定未知参数。model指定变量分布，可以用分布表示，也可以用似然函数表示。如果需要用转换后的数据（比如取对数）估计数据，就需要增加一个模块transformed data。如果需要对未知参数进行转换，则需要增加一个模块transformed parameters表示原始参数与转换参数的联系。有时还会增加一个模块generated quantities。任何可以根据模型计算出来的结果都可以在这里进行评估（比如R2）。更重要的是，它和其他参数一样，有一个分布。  
&emsp;&emsp; 需要指出的是，Stan中的赋值是 =，而分布用～指定，注释用//或者\* \*指定。注意，与教材正态分布的表示不同，RStan语句里的normal(·, ·)第二个参数表示的是标准差，而不是方差。   

&emsp;&emsp; ③准备数据（通常是一个列表）        
       
&emsp;&emsp; ④拟合模型并汇总        
  
&emsp;&emsp; 从模型拟合函数返回的对象是类stan的S4对象stanfit。       
&emsp;&emsp; ⑤诊断与其他        
&emsp;&emsp; 可以使用典型的贝叶斯诊断工具，如轨迹图、密度图等。此外rstan包带有模型比较功能，如WAIC和loo函数。        

## 一个例子  

```{r cache=TRUE}
mystan <- "
data {
  int < lower = 1 > n; 
  vector[n] y; 
}
parameters {
  real mu; 
}
model {
// priors
  mu ~ normal(0.0, 5); 
// likelihood
  y ~ normal(mu, 2);
}
"
write(mystan,file = "mystan.stan")  #写入硬盘
set.seed( 123 ) 	#随机种子
n <- 100 			#样本量
mu_chosen <- 5 		#均值μ
sigma_chosen <- 2 		#标准差σ
y <- rnorm(n, mu_chosen, sigma_chosen) 		#生成n个正态随机数

# ③准备数据（通常是一个列表）
data_for_Stan <- list(y = y, n = length(y))
# ④拟合模型并汇总
fit <- stan(file = "mystan.stan", data = data_for_Stan)
fit

# conjugate
mystan_conjugate <- "
data {
  int < lower = 1 > n; 
  vector[n] y; 
}
parameters {
  real mu;
  real<lower=0> sigma2; 
}
transformed parameters {
  real<lower=0> sigma;
  sigma = sqrt(sigma2);
}
model {
  mu ~ normal(0.0,100);
  sigma2 ~ inv_gamma(0.001,0.001); 
  y ~ normal(mu,sigma);
}
"
write(mystan_conjugate,file = "mystan_conjugate.stan")  #写入硬盘
fit_conjugate <- stan(file = "mystan_conjugate.stan", data = data_for_Stan)
fit_conjugate
#weakly 
mystan_weakly <- "
data {
  int < lower = 1 > n; 
  vector[n] y; 
}
parameters {
  real mu; 
  real < lower = 0 > sigma; 
}
model {
  mu ~ normal(0.0, 100); 
  sigma ~ cauchy(1, 10); 
  y ~ normal(mu, sigma);
}
"
write(mystan_weakly,file = "mystan_weakly.stan")  #写入硬盘
fit_weakly <- stan(file = "mystan_weakly.stan", data = data_for_Stan)
fit_weakly

# jeffreys
mystan_jeffreys <- "
data {
  int < lower = 1 > n; 
  vector[n] y; 
}
parameters {
  real mu; 
  real < lower = 0 > sigma; 
}
model {
  target += -2*log(sigma);
  target += normal_lpdf(y | mu, sigma);
  
}
"
write(mystan_jeffreys,file = "mystan_jeffreys.stan")  #写入硬盘
fit_jeffreys <- stan(file = "mystan_jeffreys.stan", data = data_for_Stan)
fit_jeffreys
```

# 第五章 贝叶斯决策              

## 1.决策问题三要素       

1.状态集 $\Theta=\{\theta \}$     
&emsp;&emsp;状态集$\Theta$ 可以只含有限个状态，也可以含有无穷个状态。   
&emsp;&emsp;状态可以用实数表示，此时状态称为状态参数，简称为参数。 
状态集$\Theta$ 常由一些实数组成，这样的状态集又称为参数空间。   
常见的参数空间是一个区间（a，b）。

2.行动集$\mathscr{A}=\{a\}$      
&emsp;&emsp;一般行动集至少有两个行动，供人们决策只用。

3.损失函数$L(\theta,a)$  
&emsp;&emsp;在一个决策问题中假设状态集为$\Theta=\{\theta\}$,行动集为$\mathscr{A}=\{a\}$，而定义在$\Theta\times\mathscr{A}$ 上的二元函数$L(\theta,a)$称为损失函数。   

&emsp;&emsp;由收益函数容易获得损失函数。当自然界（或社会）处于$\theta$时，最大收益为$\max_{a \in \mathscr{A}} Q(\theta,a)$,此时采取行动a所引起的损失为
\[L(\theta,a)= \max_{a \in \mathscr{A}} Q(\theta,a)- Q(\theta,a)\]

&emsp;&emsp;类似地，当决策用支付函数$W(\theta,a)$度量时，由于它时越小越好，自然界（或社会）处于$\theta$时的最小支付为\[\min_{a \in \mathscr{A}} W(\theta,a)\]


## 2.贝叶斯决策问题       
&emsp;&emsp;仅使用先验信息的决策问题称为**无数据（或无样本信息）的决策问题**。    
&emsp;&emsp;仅使用抽样信息的决策问题称为**统计决策问题**。    
&emsp;&emsp;先验信息和抽样信息都用的决策问题称为**贝叶斯决策问题**。    

## 3.决策函数       
&emsp;&emsp;*定义*: 在给定的贝叶斯决策问题中D={$\delta(x)$}是其决策函数类，则称
\[R(\delta|x)=E^{\theta|x}[L(\theta,\delta(x))],x \in \chi,theta \in \Theta\] 
&emsp;&emsp;为决策函数$\delta=\delta(x)$的后验风险。假如在决策函数类D中存在这样的决策函数$\delta'=\delta'(x)$,它在D中具有最小的后验风险，即
\[R(\delta'|x)= \min_{\delta \in D} R(\delta(x)|x)\]
&emsp;&emsp;则称$\delta'(x)$为后验风险准则下的最优决策函数，或称*贝叶斯决策函数，或贝叶斯解*。   
&emsp;&emsp;当参数空间$\Theta$与行动集$\mathscr{A}$ 相同，均为某个实数集时，满足上式的$\delta'(x)$又称为$\theta$的贝叶斯解或贝叶斯估计。    
&emsp;&emsp;这里应着重强调的是定义2.2.2中的前提，即在给定贝叶斯决策问题中讨论贝叶斯解或贝叶斯估计。所谓“给定贝叶斯决策问题”主要是指给定如下三个前提：   

&emsp;&emsp;样本$x$的联合密度函数$p(x|\theta)$;

&emsp;&emsp;参数空间$\Theta$上的先验分布$\pi(\theta)$;

&emsp;&emsp;定义在$\Theta \times \mathscr{A}$上的损失函数$L(\theta,a)$。

&emsp;&emsp;另外，从贝叶斯统计看，一个贝叶斯决策问题比一个贝叶斯推断问题多一个损失函数。或者说，把损失函数引进统计推断就构成贝叶斯决策问题。这样就把贝叶斯推断与经济效益联系起来了。以后按后验平均损失越小越好来进行统计推断，从而形成贝叶斯决策。

## 4.例子       
&emsp;&emsp;某制药厂制成一种新的止痛剂。为了决定新药是否投放市场，投放多少，价格如何等问题，需要了解此种新的止痛剂在市场的占有率$\theta$。
假如厂长采用[0,1]上的均匀分布作为$\theta$的先验分布;    
如果从特约经销店得知，在$n$个购买止痛剂的顾客中有$x$人买了新的止痛剂。这是$X \sim b(n,\theta)$。   
&emsp;&emsp;损失函数是线性的
\[ L(\theta,\delta) = \left \{
\begin{array}{rl}
\delta-\theta, &  0 < \theta<\delta \\
\theta-\delta, &  \delta \leq \theta \leq 1
\end{array} \right.
\]
&emsp;&emsp;药厂厂长对市场占有率$\theta$无任何先验信息。另外在市场调查中，在n个购买止痛剂的顾客中又$x$人买了新的止痛剂，这时可得$\theta$的后验分布
\[\theta |x \sim Be(x+1,n-x+1)\]
&emsp;&emsp;在后验风险准则下对$\theta$做出贝叶斯估计。
      

